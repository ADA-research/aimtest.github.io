---
layout: default
title: Hyperparameter Optimisation for Machine Learning summer term 2024
organisers: 'wskaf,tsnelleman,nkocher,hshavit,hhoos'
---

<div class="wrapper">
  <div class="box">

  <h1>Hyperparameter Optimisation for Machine Learning, Summer Term 2024</h1>

  <h3>Material</h3>

  <ul>
    <!--li><a href="data/EC_kickoff_presentation.pdf">Kickoff presentation slides</a></li-->
    <!--li><a href="data/EC_information.pdf">Detailed seminar information</a></li-->
  </ul>

  <h3>Overview</h3>

  <p>Hyperparameter Optimisation (HPO), also known as Hyperparameter Tuning, is the process of searching for a configuration of hyperparameters that yields good performance of a model or a learning algorithm. This process is challenging, and many machine learning algorithms are expensive to run and evaluate.</p>

  <p>In this lab, you will get hands-on experience with different HPO methods. Starting with both simple grid and random search, you will learn how to implement and analyse HPO from scratch. The lab then introduces more sophisticated model-free and model-based approaches such as Bayesian optimisation. You will focus on having clean, robust, and efficient code.</p>

  <p>The lab will be graded according to the following elements: 
    <ul>
      <li>Coding assignments</li>
      <li>A final presentation</li>
      <li>Discussion after the final presentation</li>
    </ul>
  </p>

  <p>The lab is fully conducted in English.</p>

  <h3>Prerequisites</h3>

  <p>Good knowledge of Python programming language. Familiarity with basic ML models (e.g. linear regression, decision trees, random forests, SVMs, â€¦etc.).</p>

  <h3>Registration</h3>

  <p>Registration to the seminar is handled via the <a href="https://supra.informatik.rwth-aachen.de/" class="external">SuPra system</a>.</p>

  <!--h3>Seminar topics</h3-->

  <h3>Organisers</h3>

  

  </div>
</div>
